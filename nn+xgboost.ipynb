{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\DL_Homework\\Kaggle2_Titanic\\Project_Titanic\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272/272 [==============================] - 1s 3ms/step - loss: 1.1094 - mse: 1.1094 - val_loss: 0.2608 - val_mse: 0.2608\n",
      "Epoch 2/1000\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.1991 - mse: 0.1991 - val_loss: 0.1456 - val_mse: 0.1456\n",
      "Epoch 3/1000\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.1578 - mse: 0.1578 - val_loss: 0.1441 - val_mse: 0.1441\n",
      "Epoch 4/1000\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.1488 - mse: 0.1488 - val_loss: 0.1355 - val_mse: 0.1355\n",
      "Epoch 5/1000\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.1395 - mse: 0.1395 - val_loss: 0.1265 - val_mse: 0.1265\n",
      "Epoch 6/1000\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.1404 - mse: 0.1404 - val_loss: 0.1277 - val_mse: 0.1277\n",
      "Epoch 7/1000\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.1377 - mse: 0.1377 - val_loss: 0.1287 - val_mse: 0.1287\n",
      "Epoch 8/1000\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.1305 - mse: 0.1305 - val_loss: 0.1301 - val_mse: 0.1301\n",
      "Epoch 9/1000\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.1339 - mse: 0.1339 - val_loss: 0.1269 - val_mse: 0.1269\n",
      "Epoch 10/1000\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.1321 - mse: 0.1321 - val_loss: 0.1253 - val_mse: 0.1253\n",
      "Epoch 11/1000\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.1379 - mse: 0.1379 - val_loss: 0.1197 - val_mse: 0.1197\n",
      "Epoch 12/1000\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.1299 - mse: 0.1299 - val_loss: 0.1404 - val_mse: 0.1404\n",
      "Epoch 13/1000\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.1253 - mse: 0.1253 - val_loss: 0.1500 - val_mse: 0.1500\n",
      "Epoch 14/1000\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.1274 - mse: 0.1274 - val_loss: 0.1346 - val_mse: 0.1346\n",
      "Epoch 15/1000\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.1305 - mse: 0.1305 - val_loss: 0.1254 - val_mse: 0.1254\n",
      "Epoch 16/1000\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.1259 - mse: 0.1259 - val_loss: 0.1476 - val_mse: 0.1476\n",
      "Epoch 17/1000\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.1338 - mse: 0.1338 - val_loss: 0.1305 - val_mse: 0.1305\n",
      "Epoch 18/1000\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.1242 - mse: 0.1242 - val_loss: 0.1271 - val_mse: 0.1271\n",
      "Epoch 19/1000\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.1234 - mse: 0.1234 - val_loss: 0.1692 - val_mse: 0.1692\n",
      "Epoch 20/1000\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.1326 - mse: 0.1326 - val_loss: 0.1345 - val_mse: 0.1345\n",
      "Epoch 21/1000\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.1241 - mse: 0.1241 - val_loss: 0.1310 - val_mse: 0.1310\n",
      "Epoch 21: early stopping\n",
      "68/68 [==============================] - 0s 984us/step\n",
      "[14:34:09] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "23/23 [==============================] - 0s 1ms/step\n",
      "mse: 0.11512476795904485\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from xgboost import XGBRegressor as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    " # Load and pre-process your data\n",
    "data = pd.read_csv(r\"D:\\DL_Homework\\Kaggle2_Titanic\\统计建模\\数据\\data-2.csv\", encoding='gb18030')\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    " # 添加年、月、日列\n",
    "data['year'] = data['date'].dt.year\n",
    "data['month'] = data['date'].dt.month\n",
    "data['day'] = data['date'].dt.day\n",
    "# print(data.head())\n",
    "cols_to_convert = ['AQI指数', 'PM2.5', 'PM10', 'O3', 'no2', 'so2', 'co', 'T', 'Po', 'U', 'Ff', 'VV', 'RRR', 'year', 'month', 'day']\n",
    "data[cols_to_convert] = data[cols_to_convert].astype(float)\n",
    "y = data['AQI指数']\n",
    "x = data.drop(['AQI指数','date'], axis=1)\n",
    " # 进行BOX-COX变换\n",
    "y = stats.boxcox(y)[0]\n",
    " # 数据标准化\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.25, random_state=33)\n",
    "\n",
    " # Define your deep learning model\n",
    "output_dim=1\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(1, 7)),\n",
    "#     tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(128, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Dense(output_dim, activation='softmax')\n",
    "# ])\n",
    "\n",
    " # Train the model\n",
    "\n",
    " # Define early stopping callback\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    " # Train the model with early stopping\n",
    "model.compile(optimizer=Adam(lr=0.01), loss='mse', metrics=['mse'])\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=1000, batch_size=8, callbacks=[early_stop])\n",
    " # Extract dense features from the trained model\n",
    "dense_layer_model = tf.keras.Model(inputs=model.input,\n",
    "                                   outputs=model.get_layer(index=-1).output)\n",
    "dense_features = dense_layer_model.predict(x_train)\n",
    "\n",
    "# 拼接训练数据和中间层的输出\n",
    "dense_features = np.concatenate((x_train, dense_features), axis=1)\n",
    "\n",
    " # Define XGBoost model\n",
    "xgb_model = xgb()\n",
    " # Train XGBoost model on dense features\n",
    "xgb_model.fit(dense_features, y_train)\n",
    " # Evaluate the XGBoost model on validation data\n",
    "dense_val_features = dense_layer_model.predict(x_val)\n",
    "dense_val_features = np.concatenate((x_val, dense_val_features), axis=1)\n",
    "val_pred = xgb_model.predict(dense_val_features)\n",
    " # Calculate the accuracy of the model\n",
    "mse = mean_squared_error(y_val, val_pred)\n",
    "print(\"mse:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Model       MSE    RMSE       MAE        R2     MAPE\n",
      "0  nn+xgboost  0.115125  0.3393  0.253759  0.576116  0.05169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_12756\\2005492115.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_model_eval = df_model_eval.append({'Model': 'nn+xgboost',\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    " # 创建一个空的DataFrame\n",
    "df_model_eval = pd.DataFrame(columns=['Model', 'MSE', 'RMSE', 'MAE', 'R2', 'MAPE'])\n",
    " # 循环遍历所有模型，并记录评估结果\n",
    "\n",
    "MSE = mean_squared_error(y_val, val_pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "MAE = mean_absolute_error(y_val, val_pred)\n",
    "R2 = r2_score(y_val, val_pred)\n",
    "MAPE = mean_absolute_percentage_error(y_val, val_pred)\n",
    "df_model_eval = df_model_eval.append({'Model': 'nn+xgboost',\n",
    "                                          'MSE': MSE,\n",
    "                                          'RMSE': RMSE,\n",
    "                                          'MAE': MAE,\n",
    "                                          'R2': R2,\n",
    "                                          'MAPE': MAPE},\n",
    "                                         ignore_index=True)\n",
    " # 输出表格\n",
    "print(df_model_eval)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
