{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 注意reptile"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Iteration        MSE      RMSE       MAE         R2      MAPE\n",
      "0        0.0  22.632145  4.757325  4.723523 -82.330489  0.947797\n",
      "   Iteration        MSE      RMSE       MAE         R2      MAPE\n",
      "1        1.0  20.990314  4.581519  4.545026 -76.285352  0.911384\n",
      "   Iteration        MSE      RMSE       MAE        R2      MAPE\n",
      "2        2.0  19.247978  4.387252  4.348139 -69.87015  0.871341\n",
      "   Iteration        MSE      RMSE       MAE         R2      MAPE\n",
      "3        3.0  17.447304  4.176997  4.135168 -63.240155  0.828099\n",
      "   Iteration        MSE     RMSE       MAE         R2      MAPE\n",
      "4        4.0  15.646059  3.95551  3.911036 -56.608051  0.782683\n",
      "   Iteration        MSE      RMSE       MAE        R2      MAPE\n",
      "5        5.0  13.894117  3.727481  3.680271 -50.15749  0.735965\n",
      "   Iteration        MSE      RMSE       MAE         R2      MAPE\n",
      "6        6.0  12.221722  3.495958  3.445887 -43.999804  0.688559\n",
      "   Iteration        MSE      RMSE       MAE         R2     MAPE\n",
      "7        7.0  10.694551  3.270252  3.217274 -38.376835  0.64235\n",
      "   Iteration       MSE      RMSE       MAE         R2      MAPE\n",
      "8        8.0  9.289287  3.047833  2.991801 -33.202718  0.596813\n",
      "   Iteration      MSE     RMSE       MAE         R2     MAPE\n",
      "9        9.0  8.03802  2.83514  2.776174 -28.595613  0.55332\n",
      "    Iteration       MSE      RMSE       MAE         R2      MAPE\n",
      "10       10.0  6.921271  2.630831  2.568695 -24.483797  0.511487\n",
      "    Iteration      MSE      RMSE       MAE         R2      MAPE\n",
      "11       11.0  5.92573  2.434282  2.368645 -20.818259  0.471177\n",
      "    Iteration       MSE     RMSE       MAE         R2      MAPE\n",
      "12       12.0  5.068893  2.25142  2.182107 -17.663428  0.433603\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "13       13.0  4.322806  2.079136  2.005852 -14.91637  0.398115\n",
      "    Iteration       MSE      RMSE       MAE         R2      MAPE\n",
      "14       14.0  3.678287  1.917886  1.840993 -12.543282  0.364984\n",
      "    Iteration       MSE      RMSE       MAE         R2      MAPE\n",
      "15       15.0  3.118001  1.765786  1.684745 -10.480332  0.333546\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "16       16.0  2.640191  1.624866  1.539188 -8.721057  0.304282\n",
      "    Iteration       MSE      RMSE      MAE       R2      MAPE\n",
      "17       17.0  2.243991  1.497996  1.40785 -7.26227  0.277933\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "18       18.0  1.884118  1.372632  1.277147 -5.937233  0.251674\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "19       19.0  1.582018  1.257783  1.156907 -4.824915  0.227528\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "20       20.0  1.338206  1.156809  1.052031 -3.927213  0.206583\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "21       21.0  1.127763  1.061962  0.953542 -3.152371  0.186969\n",
      "    Iteration       MSE      RMSE      MAE        R2      MAPE\n",
      "22       22.0  0.953351  0.976397  0.86399 -2.510196  0.169109\n",
      "    Iteration       MSE    RMSE       MAE        R2      MAPE\n",
      "23       23.0  0.817577  0.9042  0.789305 -2.010281  0.154251\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "24       24.0  0.699139  0.836145  0.719862 -1.574196  0.140521\n",
      "    Iteration       MSE     RMSE       MAE        R2      MAPE\n",
      "25       25.0  0.605844  0.77836  0.661202 -1.230688  0.128953\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "26       26.0  0.532192  0.729515  0.613086 -0.959505  0.119535\n",
      "    Iteration       MSE      RMSE       MAE        R2     MAPE\n",
      "27       27.0  0.470145  0.685671  0.570156 -0.731053  0.11111\n",
      "    Iteration       MSE      RMSE      MAE        R2      MAPE\n",
      "28       28.0  0.419589  0.647757  0.53455 -0.544905  0.104177\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "29       29.0  0.379536  0.616065  0.505398 -0.397434  0.098554\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "30       30.0  0.338986  0.582225  0.474145 -0.248132  0.092506\n",
      "    Iteration       MSE      RMSE       MAE       R2      MAPE\n",
      "31       31.0  0.308554  0.555476  0.450183 -0.13608  0.087898\n",
      "    Iteration      MSE      RMSE       MAE       R2      MAPE\n",
      "32       32.0  0.28317  0.532138  0.429048 -0.04262  0.083844\n",
      "    Iteration       MSE      RMSE       MAE        R2    MAPE\n",
      "33       33.0  0.262129  0.511986  0.410455  0.034853  0.0803\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "34       34.0  0.241072  0.490991  0.390934  0.112382  0.076597\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "35       35.0  0.224897  0.474234  0.375687  0.171938  0.073736\n",
      "    Iteration       MSE     RMSE      MAE        R2      MAPE\n",
      "36       36.0  0.211637  0.46004  0.36278  0.220764  0.071287\n",
      "    Iteration       MSE      RMSE      MAE        R2      MAPE\n",
      "37       37.0  0.203306  0.450894  0.35498  0.251438  0.069784\n",
      "    Iteration       MSE      RMSE       MAE        R2     MAPE\n",
      "38       38.0  0.192646  0.438914  0.344844  0.290688  0.06791\n",
      "    Iteration       MSE     RMSE       MAE        R2      MAPE\n",
      "39       39.0  0.182534  0.42724  0.334751  0.327919  0.066067\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "40       40.0  0.176231  0.419798  0.328054  0.351128  0.064836\n",
      "    Iteration       MSE      RMSE       MAE       R2      MAPE\n",
      "41       41.0  0.168489  0.410475  0.319421  0.37963  0.063264\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "42       42.0  0.163263  0.404058  0.313579  0.398873  0.062221\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "43       43.0  0.159208  0.399009  0.309222  0.413804  0.061439\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "44       44.0  0.155848  0.394776  0.305543  0.426173  0.060783\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "45       45.0  0.152683  0.390747  0.302125  0.437827  0.060193\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "46       46.0  0.150688  0.388185  0.299628  0.445175  0.059728\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "47       47.0  0.148299  0.385096  0.296836  0.453972  0.059248\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "48       48.0  0.146361  0.382572  0.294854  0.461105  0.058879\n",
      "    Iteration       MSE      RMSE      MAE        R2      MAPE\n",
      "49       49.0  0.143827  0.379245  0.29198  0.470436  0.058399\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "50       50.0  0.142222  0.377123  0.290208  0.476346  0.058087\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "51       51.0  0.141171  0.375727  0.289213  0.480214  0.057896\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "52       52.0  0.139606  0.373639  0.287559  0.485976  0.057621\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "53       53.0  0.138157  0.371695  0.285859  0.491313  0.057327\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "54       54.0  0.136703  0.369734  0.284104  0.496665  0.057036\n",
      "    Iteration      MSE      RMSE       MAE        R2      MAPE\n",
      "55       55.0  0.13534  0.367886  0.282509  0.501683  0.056807\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "56       56.0  0.134554  0.366816  0.281487  0.504578  0.056608\n",
      "    Iteration      MSE      RMSE       MAE        R2      MAPE\n",
      "57       57.0  0.13315  0.364897  0.279726  0.509749  0.056322\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "58       58.0  0.132158  0.363535  0.278444  0.513401  0.056121\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "59       59.0  0.131467  0.362583  0.277676  0.515946  0.056002\n",
      "    Iteration       MSE      RMSE       MAE       R2      MAPE\n",
      "60       60.0  0.130507  0.361257  0.276429  0.51948  0.055853\n",
      "    Iteration       MSE      RMSE       MAE       R2      MAPE\n",
      "61       61.0  0.130015  0.360576  0.275325  0.52129  0.055658\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "62       62.0  0.129182  0.359419  0.274533  0.524357  0.055554\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "63       63.0  0.128879  0.358997  0.274248  0.525473  0.055436\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "64       64.0  0.128565  0.358559  0.273993  0.526631  0.055404\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "65       65.0  0.127937  0.357683  0.273333  0.528942  0.055361\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "66       66.0  0.127567  0.357165  0.273327  0.530304  0.055412\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "67       67.0  0.127131  0.356554  0.272717  0.531909  0.055265\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "68       68.0  0.126938  0.356284  0.272494  0.532619  0.055228\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "69       69.0  0.127074  0.356474  0.272525  0.532121  0.055163\n",
      "    Iteration       MSE      RMSE      MAE       R2      MAPE\n",
      "70       70.0  0.126973  0.356333  0.27236  0.53249  0.055165\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "71       71.0  0.126766  0.356042  0.272129  0.533253  0.055062\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "72       72.0  0.126558  0.355749  0.271991  0.534021  0.055015\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "73       73.0  0.126252  0.355319  0.271733  0.535148  0.054979\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "74       74.0  0.126193  0.355236  0.271704  0.535364  0.054916\n",
      "    Iteration       MSE      RMSE       MAE        R2     MAPE\n",
      "75       75.0  0.125646  0.354466  0.271161  0.537377  0.05488\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "76       76.0  0.125449  0.354188  0.270778  0.538102  0.054837\n",
      "    Iteration       MSE    RMSE       MAE       R2      MAPE\n",
      "77       77.0  0.125528  0.3543  0.270798  0.53781  0.054878\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "78       78.0  0.125024  0.353587  0.270183  0.539667  0.054797\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "79       79.0  0.124815  0.353292  0.269774  0.540437  0.054694\n",
      "    Iteration       MSE      RMSE       MAE       R2      MAPE\n",
      "80       80.0  0.124627  0.353025  0.269322  0.54113  0.054675\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "81       81.0  0.124439  0.352759  0.269011  0.541823  0.054664\n",
      "    Iteration       MSE      RMSE       MAE        R2     MAPE\n",
      "82       82.0  0.124246  0.352486  0.268786  0.542531  0.05456\n",
      "    Iteration       MSE      RMSE       MAE        R2     MAPE\n",
      "83       83.0  0.124145  0.352342  0.268557  0.542904  0.05457\n",
      "    Iteration       MSE      RMSE       MAE       R2      MAPE\n",
      "84       84.0  0.124331  0.352606  0.268962  0.54222  0.054614\n",
      "    Iteration       MSE      RMSE      MAE        R2      MAPE\n",
      "85       85.0  0.124446  0.352769  0.26903  0.541797  0.054554\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "86       86.0  0.124321  0.352592  0.268892  0.542255  0.054523\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "87       87.0  0.124364  0.352653  0.268911  0.542097  0.054523\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "88       88.0  0.124282  0.352537  0.268743  0.542398  0.054523\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "89       89.0  0.124023  0.352169  0.268112  0.543352  0.054431\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "90       90.0  0.123881  0.351968  0.267814  0.543874  0.054377\n",
      "    Iteration       MSE      RMSE       MAE        R2     MAPE\n",
      "91       91.0  0.123782  0.351826  0.267691  0.544241  0.05431\n",
      "    Iteration       MSE     RMSE      MAE        R2      MAPE\n",
      "92       92.0  0.123791  0.35184  0.26776  0.544206  0.054358\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "93       93.0  0.123725  0.351745  0.267797  0.544452  0.054344\n",
      "    Iteration       MSE      RMSE      MAE       R2      MAPE\n",
      "94       94.0  0.123516  0.351448  0.26707  0.54522  0.054286\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "95       95.0  0.123258  0.351082  0.266941  0.546168  0.054256\n",
      "    Iteration      MSE      RMSE       MAE        R2     MAPE\n",
      "96       96.0  0.12319  0.350985  0.267177  0.546419  0.05424\n",
      "    Iteration      MSE      RMSE       MAE        R2      MAPE\n",
      "97       97.0  0.12309  0.350842  0.267208  0.546788  0.054251\n",
      "    Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "98       98.0  0.123007  0.350723  0.267121  0.547095  0.054259\n",
      "    Iteration      MSE      RMSE       MAE       R2      MAPE\n",
      "99       99.0  0.12288  0.350543  0.267013  0.54756  0.054237\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "100      100.0  0.122792  0.350417  0.266892  0.547885  0.054253\n",
      "     Iteration       MSE      RMSE       MAE       R2      MAPE\n",
      "101      101.0  0.122745  0.350349  0.266798  0.54806  0.054255\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "102      102.0  0.122478  0.349969  0.266573  0.549041  0.054178\n",
      "     Iteration       MSE      RMSE       MAE       R2      MAPE\n",
      "103      103.0  0.122307  0.349725  0.266037  0.54967  0.054127\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "104      104.0  0.121951  0.349214  0.265611  0.550984  0.054033\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "105      105.0  0.121855  0.349078  0.265555  0.551334  0.054003\n",
      "     Iteration       MSE     RMSE       MAE        R2      MAPE\n",
      "106      106.0  0.121899  0.34914  0.265558  0.551175  0.054012\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "107      107.0  0.121778  0.348967  0.265458  0.551619  0.053998\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "108      108.0  0.121799  0.348997  0.265207  0.551542  0.053952\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "109      109.0  0.121618  0.348738  0.265196  0.552207  0.053948\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "110      110.0  0.121732  0.348902  0.265486  0.551787  0.053984\n",
      "     Iteration       MSE     RMSE       MAE       R2      MAPE\n",
      "111      111.0  0.121438  0.34848  0.265169  0.55287  0.053908\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "112      112.0  0.121239  0.348195  0.264795  0.553602  0.053806\n",
      "     Iteration       MSE     RMSE       MAE        R2      MAPE\n",
      "113      113.0  0.121438  0.34848  0.265043  0.552869  0.053795\n",
      "     Iteration       MSE     RMSE       MAE        R2      MAPE\n",
      "114      114.0  0.121271  0.34824  0.264834  0.553487  0.053793\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "115      115.0  0.121135  0.348044  0.264542  0.553988  0.053752\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "116      116.0  0.121123  0.348027  0.264419  0.554031  0.053785\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "117      117.0  0.121005  0.347857  0.264229  0.554466  0.053735\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "118      118.0  0.120771  0.347521  0.264092  0.555326  0.053698\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "119      119.0  0.120815  0.347584  0.264153  0.555166  0.053752\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "120      120.0  0.120686  0.347398  0.264017  0.555641  0.053746\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "121      121.0  0.120751  0.347492  0.264044  0.555401  0.053726\n",
      "     Iteration      MSE      RMSE       MAE        R2      MAPE\n",
      "122      122.0  0.12075  0.347491  0.264183  0.555405  0.053713\n",
      "     Iteration     MSE      RMSE       MAE        R2      MAPE\n",
      "123      123.0  0.1206  0.347276  0.263997  0.555955  0.053662\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "124      124.0  0.120528  0.347171  0.263818  0.556222  0.053621\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "125      125.0  0.120405  0.346994  0.263323  0.556674  0.053534\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "126      126.0  0.120481  0.347104  0.263673  0.556395  0.053617\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "127      127.0  0.120467  0.347084  0.263555  0.556445  0.053632\n",
      "     Iteration       MSE      RMSE       MAE        R2     MAPE\n",
      "128      128.0  0.120532  0.347177  0.263604  0.556207  0.05362\n",
      "     Iteration       MSE      RMSE       MAE       R2      MAPE\n",
      "129      129.0  0.120572  0.347235  0.263605  0.55606  0.053585\n",
      "     Iteration      MSE      RMSE       MAE        R2      MAPE\n",
      "130      130.0  0.12062  0.347304  0.263251  0.555883  0.053582\n",
      "     Iteration       MSE      RMSE       MAE        R2     MAPE\n",
      "131      131.0  0.120658  0.347359  0.263252  0.555742  0.05359\n",
      "     Iteration       MSE      RMSE      MAE        R2      MAPE\n",
      "132      132.0  0.120953  0.347784  0.26354  0.554655  0.053721\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "133      133.0  0.121169  0.348093  0.263747  0.553861  0.053754\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "134      134.0  0.121258  0.348221  0.263807  0.553534  0.053819\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "135      135.0  0.121186  0.348118  0.263656  0.553798  0.053791\n",
      "     Iteration       MSE     RMSE       MAE        R2      MAPE\n",
      "136      136.0  0.121292  0.34827  0.263888  0.553409  0.053802\n",
      "     Iteration       MSE      RMSE       MAE        R2     MAPE\n",
      "137      137.0  0.121165  0.348088  0.263684  0.553875  0.05371\n",
      "     Iteration       MSE      RMSE       MAE        R2     MAPE\n",
      "138      138.0  0.121328  0.348322  0.263711  0.553276  0.05374\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "139      139.0  0.121448  0.348495  0.263778  0.552833  0.053777\n",
      "     Iteration       MSE     RMSE       MAE        R2    MAPE\n",
      "140      140.0  0.121431  0.34847  0.263878  0.552896  0.0538\n",
      "     Iteration       MSE      RMSE      MAE        R2      MAPE\n",
      "141      141.0  0.121545  0.348633  0.26409  0.552478  0.053863\n",
      "     Iteration       MSE      RMSE       MAE        R2     MAPE\n",
      "142      142.0  0.121371  0.348383  0.263998  0.553119  0.05382\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "143      143.0  0.121196  0.348132  0.264179  0.553763  0.053793\n",
      "     Iteration      MSE      RMSE       MAE        R2      MAPE\n",
      "144      144.0  0.12118  0.348109  0.264106  0.553822  0.053787\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "145      145.0  0.120962  0.347796  0.263992  0.554623  0.053751\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "146      146.0  0.120941  0.347766  0.264101  0.554699  0.053761\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "147      147.0  0.120698  0.347417  0.264068  0.555595  0.053695\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "148      148.0  0.120734  0.347467  0.264163  0.555464  0.053731\n",
      "     Iteration       MSE      RMSE      MAE        R2      MAPE\n",
      "149      149.0  0.120489  0.347115  0.26415  0.556366  0.053727\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "150      150.0  0.120463  0.347077  0.264187  0.556462  0.053778\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "151      151.0  0.120108  0.346566  0.263751  0.557767  0.053644\n",
      "     Iteration      MSE     RMSE       MAE       R2      MAPE\n",
      "152      152.0  0.11982  0.34615  0.263507  0.55883  0.053602\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "153      153.0  0.119902  0.346269  0.263476  0.558526  0.053545\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "154      154.0  0.119732  0.346023  0.263449  0.559152  0.053533\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "155      155.0  0.119478  0.345657  0.263043  0.560086  0.053493\n",
      "     Iteration      MSE      RMSE       MAE        R2      MAPE\n",
      "156      156.0  0.11952  0.345716  0.263192  0.559934  0.053515\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "157      157.0  0.119293  0.345388  0.263081  0.560769  0.053541\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "158      158.0  0.119144  0.345173  0.262999  0.561316  0.053527\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "159      159.0  0.119195  0.345247  0.263023  0.561128  0.053536\n",
      "     Iteration       MSE     RMSE       MAE        R2      MAPE\n",
      "160      160.0  0.119336  0.34545  0.263199  0.560612  0.053595\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "161      161.0  0.119338  0.345454  0.263358  0.560602  0.053599\n",
      "     Iteration      MSE      RMSE       MAE        R2      MAPE\n",
      "162      162.0  0.11934  0.345457  0.263302  0.560594  0.053585\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "163      163.0  0.119373  0.345505  0.263233  0.560473  0.053557\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "164      164.0  0.119558  0.345772  0.263466  0.559792  0.053545\n",
      "     Iteration       MSE      RMSE      MAE        R2    MAPE\n",
      "165      165.0  0.119644  0.345896  0.26347  0.559475  0.0536\n",
      "     Iteration       MSE      RMSE      MAE        R2      MAPE\n",
      "166      166.0  0.119817  0.346146  0.26349  0.558839  0.053631\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "167      167.0  0.119717  0.346001  0.263289  0.559209  0.053573\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "168      168.0  0.119819  0.346148  0.263247  0.558833  0.053583\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "169      169.0  0.119777  0.346088  0.263217  0.558987  0.053513\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "170      170.0  0.119852  0.346197  0.263329  0.558709  0.053555\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "171      171.0  0.119865  0.346216  0.263267  0.558662  0.053553\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "172      172.0  0.119876  0.346231  0.263171  0.558622  0.053522\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "173      173.0  0.119886  0.346245  0.263258  0.558587  0.053488\n",
      "     Iteration       MSE      RMSE       MAE        R2      MAPE\n",
      "174      174.0  0.120013  0.346429  0.263358  0.558118  0.053525\n",
      "     Iteration       MSE      RMSE      MAE        R2      MAPE\n",
      "175      175.0  0.120047  0.346478  0.26335  0.557992  0.053561\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [64], line 118\u001B[0m\n\u001B[0;32m    116\u001B[0m model_after \u001B[38;5;241m=\u001B[39m MLP(input_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m15\u001B[39m, output_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    117\u001B[0m train_losses_after \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m--> 118\u001B[0m reptile(model_after, \u001B[38;5;241m2000\u001B[39m, sample_task, perform_k_training_steps, k\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)\n",
      "Cell \u001B[1;32mIn [64], line 18\u001B[0m, in \u001B[0;36mreptile\u001B[1;34m(model, nb_iterations, sample_task, perform_k_training_steps, k, epsilon)\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(nb_iterations):\n\u001B[0;32m     17\u001B[0m     task \u001B[38;5;241m=\u001B[39m sample_task()\n\u001B[1;32m---> 18\u001B[0m     phi_tilde \u001B[38;5;241m=\u001B[39m \u001B[43mperform_k_training_steps\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;66;03m# Update phi\u001B[39;00m\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n",
      "Cell \u001B[1;32mIn [64], line 109\u001B[0m, in \u001B[0;36mperform_k_training_steps\u001B[1;34m(model, task, k, batch_size)\u001B[0m\n\u001B[0;32m    107\u001B[0m x_batch \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(train_x[batch_idx], dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[0;32m    108\u001B[0m target \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(train_y[batch_idx], dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m--> 109\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fct(\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_batch\u001B[49m\u001B[43m)\u001B[49m, target)\n\u001B[0;32m    110\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m    111\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32mD:\\DL_Homework\\Kaggle2_Titanic\\Project_Titanic\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn [64], line 71\u001B[0m, in \u001B[0;36mMLP.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     69\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc1(x)\n\u001B[0;32m     70\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(out)\n\u001B[1;32m---> 71\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfc2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     72\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(out)\n\u001B[0;32m     73\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc3(out)\n",
      "File \u001B[1;32mD:\\DL_Homework\\Kaggle2_Titanic\\Project_Titanic\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\DL_Homework\\Kaggle2_Titanic\\Project_Titanic\\venv\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score, mean_absolute_error\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import Callable\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_losses_after = []\n",
    "def reptile(model: nn.Module, nb_iterations: int, sample_task: Callable, perform_k_training_steps: Callable, k=15, epsilon=0.1):\n",
    "    for _ in range(nb_iterations):\n",
    "        task = sample_task()\n",
    "        phi_tilde = perform_k_training_steps(copy.deepcopy(model), task, k)\n",
    "        # Update phi\n",
    "        with torch.no_grad():\n",
    "            for p,g in zip(model.parameters(), phi_tilde):\n",
    "                p += epsilon*(g - p)\n",
    "        # 在每次迭代后评估测试集误差\n",
    "        df_model_eval = pd.DataFrame(columns=['Iteration', 'MSE', 'RMSE', 'MAE', 'R2', 'MAPE'])\n",
    "        with torch.no_grad():\n",
    "            df = pd.read_csv(r\"D:\\DL_Homework\\Kaggle2_Titanic\\统计建模\\数据\\data-2.csv\", encoding='gb18030')\n",
    "             # 将 'date' 列转换为日期时间格式\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "             # 添加年、月、日列\n",
    "            df['year'] = df['date'].dt.year\n",
    "            df['month'] = df['date'].dt.month\n",
    "            df['day'] = df['date'].dt.day\n",
    "\n",
    "            data = df\n",
    "            y = data['AQI指数']\n",
    "            x = data.drop(['AQI指数','date'], axis=1)\n",
    "             # 进行BOX-COX变换\n",
    "            y = stats.boxcox(y)[0]\n",
    "            scaler = StandardScaler()\n",
    "            x = scaler.fit_transform(x)\n",
    "\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 33)\n",
    "            x_test_tensor = torch.tensor(x_test, dtype=torch.float32).unsqueeze(1)\n",
    "            y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(-1)\n",
    "            y_pred = model(x_test_tensor)\n",
    "            test_mse = mean_squared_error(y_test_tensor, y_pred.squeeze(-1))\n",
    "\n",
    "            # train_losses_after.append(test_mse)\n",
    "            # print(test_mse)\n",
    "\n",
    "            MSE = mean_squared_error(y_test_tensor, y_pred.squeeze(-1))\n",
    "            RMSE = np.sqrt(mean_squared_error(y_test_tensor, y_pred.squeeze(-1)))\n",
    "            MAE = mean_absolute_error(y_test_tensor, y_pred.squeeze(-1))\n",
    "            R2 = r2_score(y_test_tensor, y_pred.squeeze(-1))\n",
    "            MAPE = mean_absolute_percentage_error(y_test_tensor, y_pred.squeeze(-1))\n",
    "\n",
    "            train_losses_after.append(MSE)\n",
    "        df_model_eval.loc[_] = [ _, MSE, RMSE, MAE, R2, MAPE]\n",
    "        print(df_model_eval)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 10)\n",
    "        self.fc2 = nn.Linear(10, 32)\n",
    "        self.fc3 = nn.Linear(32, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample_task():\n",
    "    # 读取数据\n",
    "    df = pd.read_csv(r\"D:\\DL_Homework\\Kaggle2_Titanic\\统计建模\\数据\\data-2.csv\", encoding='gb18030')\n",
    "     # 将 'date' 列转换为日期时间格式\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "     # 添加年、月、日列\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "\n",
    "    data = df\n",
    "    y = data['AQI指数']\n",
    "    x = data.drop(['AQI指数','date'], axis=1)\n",
    "     # 进行BOX-COX变换\n",
    "    y = stats.boxcox(y)[0]\n",
    "    scaler = StandardScaler()\n",
    "    x = scaler.fit_transform(x)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 33)\n",
    "    x = x_train\n",
    "    y = y_train\n",
    "    loss_fct = nn.MSELoss()\n",
    "    return x, y, loss_fct\n",
    "\n",
    "def perform_k_training_steps(model, task, k, batch_size=256):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "    train_x, train_y, loss_fct = task\n",
    "    for epoch in range(k * train_x.shape[0] // batch_size):\n",
    "        # print(k * train_x.shape[0] // batch_size)\n",
    "        batch_idx = np.random.choice(np.arange(len(train_x)), size=batch_size, replace=False)\n",
    "        x_batch = torch.tensor(train_x[batch_idx], dtype=torch.float32)\n",
    "        target = torch.tensor(train_y[batch_idx], dtype=torch.float32).unsqueeze(-1)\n",
    "        loss = loss_fct(model(x_batch), target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model.parameters()\n",
    "\n",
    "# 训练经过元学习的模型，并记录loss值\n",
    "model_after = MLP(input_dim=15, output_dim=1)\n",
    "train_losses_after = []\n",
    "reptile(model_after, 2000, sample_task, perform_k_training_steps, k=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 训练经过元学习的模型，并记录loss值\n",
    "model_after = LSTM(input_dim=15, hidden_dim=64, output_dim=1)\n",
    "train_losses_after = []\n",
    "reptile(model_after, 110, sample_task, perform_k_training_steps, k=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"D:\\DL_Homework\\Kaggle2_Titanic\\统计建模\\数据\\data-2.csv\", encoding='gb18030')\n",
    "# Convert 'date' column to datetime format\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "# Add year, month, day columns\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day\n",
    "\n",
    "data = df\n",
    "y = data['AQI指数']\n",
    "x = data.drop(['AQI指数', 'date'], axis=1)\n",
    "# Perform BOX-COX transformation\n",
    "y = stats.boxcox(y)[0]\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=33)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred_after = model_after(torch.tensor(x_test, dtype=torch.float32))\n",
    "MSE = mean_squared_error(y_test, torch.tensor(y_pred_after).squeeze(-1))\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, torch.tensor(y_pred_after).squeeze(-1)))\n",
    "MAE = mean_absolute_error(y_test, torch.tensor(y_pred_after).squeeze(-1))\n",
    "MAE = mean_absolute_error(y_test, torch.tensor(y_pred_after).squeeze(-1))\n",
    "R2 = r2_score(y_test, torch.tensor(y_pred_after).squeeze(-1))\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_pred - y_true) / y_true))\n",
    "MAPE = mean_absolute_percentage_error(y_test, torch.tensor(y_pred_after).squeeze(-1))\n",
    "print(\"===========================\")\n",
    "print(\"MSE:\", MSE)\n",
    "print(\"RMSE:\", RMSE)\n",
    "print(\"MAE:\", MAE)\n",
    "print(\"R2:\", R2)\n",
    "print(\"===========================\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 训练不经过元学习的模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 训练不经历元学习的模型，并记录loss值\n",
    "    model_before = MLP(input_dim=15, output_dim=1)\n",
    "    optimizer_before = torch.optim.Adam(model_before.parameters(), lr=0.01)\n",
    "    df = pd.read_csv(r\"D:\\DL_Homework\\Kaggle2_Titanic\\统计建模\\数据\\data-2.csv\", encoding='gb18030')\n",
    "     # 将 'date' 列转换为日期时间格式\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "     # 添加年、月、日列\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "\n",
    "    data = df\n",
    "    y = data['AQI指数']\n",
    "    x = data.drop(['AQI指数','date'], axis=1)\n",
    "     # 进行BOX-COX变换\n",
    "    y = stats.boxcox(y)[0]\n",
    "    scaler = StandardScaler()\n",
    "    x = scaler.fit_transform(x)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 33)\n",
    "\n",
    "    loss_fct = nn.MSELoss()\n",
    "    train_losses_before = []\n",
    "    for epoch in range(2000):\n",
    "        optimizer_before.zero_grad()\n",
    "        y_pred_before_train = model_before(torch.tensor(x_train, dtype=torch.float32))\n",
    "        loss_before_train = loss_fct(y_pred_before_train.squeeze(-1), torch.tensor(y_train, dtype=torch.float32))\n",
    "        loss_before_train.backward()\n",
    "        optimizer_before.step()\n",
    "\n",
    "\n",
    "        y_pred_before = model_before(torch.tensor(x_test, dtype=torch.float32))\n",
    "        loss_before = loss_fct(y_pred_before.squeeze(-1), torch.tensor(y_test, dtype=torch.float32))\n",
    "        train_losses_before.append(loss_before.item())\n",
    "\n",
    "\n",
    "        MSE = mean_squared_error(y_test, torch.tensor(y_pred_before).squeeze(-1))\n",
    "        RMSE = np.sqrt(mean_squared_error(y_test, torch.tensor(y_pred_before).squeeze(-1)))\n",
    "        MAE = mean_absolute_error(y_test, torch.tensor(y_pred_before).squeeze(-1))\n",
    "        MAE = mean_absolute_error(y_test, torch.tensor(y_pred_before).squeeze(-1))\n",
    "        R2 = r2_score(y_test, torch.tensor(y_pred_before).squeeze(-1))\n",
    "        def mape(y_true, y_pred):\n",
    "            return np.mean(np.abs((y_pred - y_true) / y_true))\n",
    "        MAPE = mean_absolute_percentage_error(y_test, torch.tensor(y_pred_before).squeeze(-1))\n",
    "        print(\"===========================\")\n",
    "        print(\"MSE:\", MSE)\n",
    "        print(\"RMSE:\", RMSE)\n",
    "        print(\"MAE:\", MAE)\n",
    "        print(\"R2:\", R2)\n",
    "        print(\"===========================\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses_before)\n",
    "plt.axhline(y=min(train_losses_before), color='r', linestyle='--') # 在最低点处绘制红色虚线\n",
    "plt.title('Train Loss of Model Before Meta-Learning')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_losses_after)\n",
    "plt.axhline(y=min(train_losses_after), color='r', linestyle='--') # 在最低点处绘制红色虚线\n",
    "plt.title('Train Loss of Model After Meta-Learning')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(train_losses_before, label='Before Meta-Learning')\n",
    "plt.axhline(y=min(train_losses_before), color='r', linestyle='--') # 在Before Meta-Learning最低点处绘制红色虚线\n",
    "plt.plot(train_losses_after, label='After Meta-Learning')\n",
    "plt.axhline(y=min(train_losses_after), color='r', linestyle='--') # 在After Meta-Learning最低点处绘制红色虚线\n",
    "plt.title('Train Loss Comparison')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(train_losses_before, label='Before Meta-Learning')\n",
    "plt.plot(train_losses_after, label='After Meta-Learning')\n",
    "plt.title('Train Loss Comparison')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(train_losses_before)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(train_losses_after)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score, mean_absolute_error\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import Callable\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def reptile(model: nn.Module, nb_iterations: int, sample_task: Callable, perform_k_training_steps: Callable, k=30, epsilon=0.1):\n",
    "    for _ in tqdm(range(nb_iterations)):\n",
    "        task = sample_task()\n",
    "        phi_tilde = perform_k_training_steps(copy.deepcopy(model), task, k)\n",
    "        # Update phi\n",
    "        with torch.no_grad():\n",
    "            for p,g in zip(model.parameters(), phi_tilde):\n",
    "                p += epsilon*(g - p)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample_task():\n",
    "    data = pd.read_excel(r\"D:\\DL_Homework\\Kaggle2_Titanic\\Iris\\SMOGN\\data\\数据源信息_clean02.xls\")\n",
    "    x = data.drop(['价格'], axis=1)\n",
    "    y = data['价格']\n",
    "    y = y/y.max()\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=33)\n",
    "    x = x_train\n",
    "    y = y_train\n",
    "    loss_fct = nn.MSELoss()\n",
    "    return x, y, loss_fct\n",
    "\n",
    "def perform_k_training_steps(model, task, k, batch_size=256):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    train_x, train_y, loss_fct = task\n",
    "    for epoch in range(k * train_x.shape[0] // batch_size):\n",
    "        # print(k * train_x.shape[0] // batch_size)\n",
    "        batch_idx = np.random.choice(np.arange(len(train_x)), size=batch_size, replace=False)\n",
    "        x_batch = torch.tensor(train_x.iloc[batch_idx].values, dtype=torch.float32)\n",
    "        target = torch.tensor(train_y.iloc[batch_idx].values, dtype=torch.float32).unsqueeze(-1)\n",
    "        loss = loss_fct(model(x_batch), target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model.parameters()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 训练不经历元学习的模型，并记录loss值\n",
    "    model_before = Net(input_dim=77, output_dim=1)\n",
    "    optimizer_before = torch.optim.Adam(model_before.parameters(), lr=0.01)\n",
    "    data = pd.read_excel(r\"D:\\DL_Homework\\Kaggle2_Titanic\\Iris\\SMOGN\\data\\数据源信息_clean02.xls\")\n",
    "    x = data.drop(['价格'], axis=1)\n",
    "    y = data['价格']\n",
    "    y = y/y.max()\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=33)\n",
    "    x = x_test\n",
    "    y = y_test\n",
    "    loss_fct = nn.MSELoss()\n",
    "    train_losses_before = []\n",
    "    train_rmse_before = []\n",
    "    train_mae_before = []\n",
    "    train_r2_before = []\n",
    "    train_mape_before = []\n",
    "    for epoch in range(445):\n",
    "        optimizer_before.zero_grad()\n",
    "        y_pred_before = model_before(torch.tensor(x.values, dtype=torch.float32))\n",
    "        loss_before = loss_fct(y_pred_before.squeeze(-1), torch.tensor(y.values, dtype=torch.float32))\n",
    "        loss_before.backward()\n",
    "        optimizer_before.step()\n",
    "        train_losses_before.append(loss_before.item())\n",
    "        RMSE = np.sqrt(mean_squared_error(y_test, torch.tensor(y_pred_before).squeeze(-1)))\n",
    "        MAE = mean_absolute_error(y_test, torch.tensor(y_pred_before).squeeze(-1))\n",
    "        R2 = r2_score(y_test, torch.tensor(y_pred_before).squeeze(-1))\n",
    "        def mape(y_true, y_pred):\n",
    "            return np.mean(np.abs((y_pred - y_true) / y_true))\n",
    "        MAPE = mean_absolute_percentage_error(y_test, torch.tensor(y_pred_before).squeeze(-1))\n",
    "\n",
    "        train_rmse_before.append(RMSE.item())\n",
    "        train_mae_before.append(MAE.item())\n",
    "        train_r2_before.append(R2.item())\n",
    "        train_mape_before.append(MAPE.item())\n",
    "\n",
    "    # 训练经过元学习的模型，并记录loss值\n",
    "    model_after = Net(input_dim=77, output_dim=1)\n",
    "    reptile(model_after, 1, sample_task, perform_k_training_steps, k=30)\n",
    "    optimizer_after = torch.optim.Adam(model_after.parameters(), lr=0.01)\n",
    "    x = x_test\n",
    "    y = y_test\n",
    "    loss_fct = nn.MSELoss()\n",
    "    train_losses_after = []\n",
    "    train_rmse_after = []\n",
    "    train_mae_after = []\n",
    "    train_r2_after = []\n",
    "    train_mape_after = []\n",
    "    for epoch in range(445):\n",
    "        optimizer_after.zero_grad()\n",
    "        y_pred_after = model_after(torch.tensor(x.values, dtype=torch.float32))\n",
    "        loss_after = loss_fct(y_pred_after.squeeze(-1), torch.tensor(y.values, dtype=torch.float32))\n",
    "        loss_after.backward()\n",
    "        optimizer_after.step()\n",
    "        train_losses_after.append(loss_after.item())\n",
    "        RMSE = np.sqrt(mean_squared_error(y_test, torch.tensor(y_pred_after).squeeze(-1)))\n",
    "        MAE = mean_absolute_error(y_test, torch.tensor(y_pred_after).squeeze(-1))\n",
    "        R2 = r2_score(y_test, torch.tensor(y_pred_after).squeeze(-1))\n",
    "        def mape(y_true, y_pred):\n",
    "            return np.mean(np.abs((y_pred - y_true) / y_true))\n",
    "        MAPE = mean_absolute_percentage_error(y_test, torch.tensor(y_pred_after).squeeze(-1))\n",
    "\n",
    "        train_rmse_after.append(RMSE.item())\n",
    "        train_mae_after.append(MAE.item())\n",
    "        train_r2_after.append(R2.item())\n",
    "        train_mape_after.append(MAPE.item())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(train_losses_before)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(train_rmse_before)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(train_mae_before)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(train_r2_before)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(train_losses_after)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(train_rmse_after)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(train_mae_after)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(train_r2_after)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
