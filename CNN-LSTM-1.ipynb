{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    " # 读取数据\n",
    "data = pd.read_csv(r\"D:\\DL_Homework\\Kaggle2_Titanic\\统计建模\\数据\\data-1.csv\", encoding='gb18030')\n",
    " # 将 'date' 列转换为日期时间格式\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    " # 添加年、月、日列\n",
    "data['year'] = data['date'].dt.year\n",
    "data['month'] = data['date'].dt.month\n",
    "data['day'] = data['date'].dt.day\n",
    "data = data.set_index('date')\n",
    "cols_to_convert = ['AQI指数', 'PM2.5', 'PM10', 'O3', 'no2', 'so2', 'co', 'T', 'Po', 'U', 'Ff', 'VV', 'RRR', 'year', 'month', 'day']\n",
    "data[cols_to_convert] = data[cols_to_convert].astype(float)\n",
    "\n",
    "# y = data['AQI指数']\n",
    "# y = stats.boxcox(y)[0]  #对数据进行BOX-COX变换\n",
    "# x = data.drop(['AQI指数'], axis=1)\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "2173"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_data(data, test_size=0.2, analysis='univariate'):\n",
    "\n",
    "    if analysis == 'univariate':\n",
    "        position = int(round(len(data) * (1-test_size)))\n",
    "        train = np.array(data[:position]).reshape(-1,1)\n",
    "        test = np.array(data[position:]).reshape(-1,1)\n",
    "\n",
    "    elif analysis == 'multivariate':\n",
    "        position = int(round(len(data) * (1-test_size)))\n",
    "        train = data[:position]\n",
    "        test = data[position:]\n",
    "\n",
    "    else:\n",
    "        print(\"Please specify if analysis is univariate or multivariate\")\n",
    "\n",
    "    return train, test\n",
    "\n",
    "def scale(data, train_split):\n",
    "\n",
    "    data_mean = data[:train_split].mean(axis=0)\n",
    "    data_std = data[:train_split].std(axis=0)\n",
    "\n",
    "    return (data - data_mean) / data_std\n",
    "\n",
    "def inv_scale(data, scaled_data, train_split):\n",
    "\n",
    "    data_mean = data[:train_split].mean(axis=0)\n",
    "    data_std = data[:train_split].std(axis=0)\n",
    "\n",
    "    return scaled_data * data_std + data_mean\n",
    "test_size = 0.25\n",
    "ddf = data\n",
    "TRAIN_SPLIT = int(round(len(ddf) * (1-test_size)))\n",
    "TRAIN_SPLIT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "(2897, 16)"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multivar_data = ddf\n",
    "multivar_data.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "multivar_data_scaled = scale(multivar_data, TRAIN_SPLIT)\n",
    "multivar_data_scaled.shape, multivar_data_scaled[0]\n",
    "\n",
    "test_size=0.2\n",
    "train, test = split_data(data=multivar_data_scaled, test_size=test_size, analysis='multivariate')\n",
    "\n",
    "\n",
    "# print(\"Shape train:\", train.shape, \"\\nShape test:\", test.shape, '\\n')\n",
    "# print(train[:9])\n",
    "# print(test[:9])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "def create_samples_multivar(data, n_input, n_output, target_index=0):\n",
    "    \"\"\"\n",
    "    Function to convert time series observations\n",
    "    into input X and output y\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "\n",
    "    # Move column defined  y target_index to first position\n",
    "    a = data[:, target_index].reshape(-1,1)\n",
    "    b = np.delete(data, target_index, axis=1)\n",
    "    data = np.concatenate((a, b), axis=1)\n",
    "\n",
    "    for i in range(n_input, len(data)): #start, stop\n",
    "        if i+n_output > len(data):\n",
    "            break\n",
    "        X.append(data[i-n_input : i, :])\n",
    "        y.append(data[i : i+n_output, 0])\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "n_input = 60 #n_input表示使用前多少个单位时间步长作为预测因变量\n",
    "n_output = 60 #n_output表示对接下来多少个时刻进行预测，此处表示对接下来60分钟的用电量进行预测\n",
    "target_index = 0 #target_index控制的是预测哪个特征变量，0表示对“Global_active_power”进行预测，1表示对“Global_reactive_power”进行预测，以此类推\n",
    "\n",
    "X_train, y_train = create_samples_multivar(train, n_input=n_input, n_output=n_output, target_index=target_index)\n",
    "X_test, y_test = create_samples_multivar(test, n_input=n_input, n_output=n_output, target_index=target_index)\n",
    "\n",
    "#\n",
    "# print(\"Shape X_train y_train:\", X_train.shape, y_train.shape,\n",
    "#       \"\\nShape X_test y_test:\", X_test.shape, y_test.shape, '\\n')\n",
    "# for i in range(1):\n",
    "#     print(X_train[i], y_train[i])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "window_size = 60\n",
    "fea_num = 16\n",
    "\n",
    "\n",
    "# model = keras.models.Sequential([\n",
    "#     keras.layers.Input((window_size, fea_num)),\n",
    "#     keras.layers.Reshape((window_size, fea_num, 1)),\n",
    "#     keras.layers.Conv2D(filters=64, kernel_size=(2,1), strides=1, padding=\"same\", activation=\"relu\"),\n",
    "#     keras.layers.MaxPooling2D(pool_size=(2,1), strides=1, padding=\"same\"),\n",
    "#     keras.layers.Conv2D(filters=64, kernel_size=(2,1), strides=1, padding=\"same\", activation=\"relu\"),\n",
    "#     keras.layers.MaxPooling2D(pool_size=(2,1), strides=1, padding=\"same\"),\n",
    "#\n",
    "#     keras.layers.Reshape((window_size, -1)),\n",
    "#     keras.layers.LSTM(64, return_sequences=False, activation=\"tanh\"),\n",
    "#     keras.layers.Dense(32, activation=\"relu\"),\n",
    "#     keras.layers.Dense(10)\n",
    "# ])\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(60,16)),\n",
    "    # tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(60)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='mse', optimizer=Adam(0.001), metrics=['mse'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 16s 82ms/step - loss: 0.8376 - mse: 0.8376\n",
      "15/15 [==============================] - 2s 33ms/step\n",
      "Epoch 1 - MSE: 0.7242 - RMSE: 0.8510 - MAE: 0.6539 - R2: 0.3095 - MAPE: 150.29%\n",
      "69/69 [==============================] - 6s 82ms/step - loss: 0.6967 - mse: 0.6967\n",
      "15/15 [==============================] - 1s 38ms/step\n",
      "Epoch 2 - MSE: 0.6963 - RMSE: 0.8345 - MAE: 0.6262 - R2: 0.3340 - MAPE: 155.22%\n",
      "69/69 [==============================] - 6s 86ms/step - loss: 0.6520 - mse: 0.6520\n",
      "15/15 [==============================] - 1s 37ms/step\n",
      "Epoch 3 - MSE: 0.7621 - RMSE: 0.8730 - MAE: 0.6679 - R2: 0.2715 - MAPE: 176.78%\n",
      "69/69 [==============================] - 6s 86ms/step - loss: 0.6236 - mse: 0.6236\n",
      "15/15 [==============================] - 1s 34ms/step\n",
      "Epoch 4 - MSE: 0.8246 - RMSE: 0.9080 - MAE: 0.7110 - R2: 0.2090 - MAPE: 187.91%\n",
      "69/69 [==============================] - 6s 85ms/step - loss: 0.6049 - mse: 0.6049\n",
      "15/15 [==============================] - 1s 34ms/step\n",
      "Epoch 5 - MSE: 0.8458 - RMSE: 0.9197 - MAE: 0.7253 - R2: 0.1924 - MAPE: 187.81%\n",
      "18/69 [======>.......................] - ETA: 4s - loss: 0.6013 - mse: 0.6013"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [102], line 18\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# Training loop\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;66;03m# Perform training epoch\u001B[39;00m\n\u001B[1;32m---> 18\u001B[0m     history \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mfit(X_train, y_train, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, verbose\u001B[38;5;241m=\u001B[39mverbose)\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;66;03m# Predict on the test set\u001B[39;00m\n\u001B[0;32m     21\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(X_test)\n",
      "File \u001B[1;32mD:\\DL_Homework\\Kaggle2_Titanic\\Project_Titanic\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mD:\\DL_Homework\\Kaggle2_Titanic\\Project_Titanic\\venv\\lib\\site-packages\\keras\\engine\\training.py:1650\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1642\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1643\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1644\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1647\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1648\u001B[0m ):\n\u001B[0;32m   1649\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1650\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1651\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1652\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32mD:\\DL_Homework\\Kaggle2_Titanic\\Project_Titanic\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mD:\\DL_Homework\\Kaggle2_Titanic\\Project_Titanic\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    877\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    879\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 880\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    882\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    883\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32mD:\\DL_Homework\\Kaggle2_Titanic\\Project_Titanic\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    909\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    910\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    911\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 912\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_no_variable_creation_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    913\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    914\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    915\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    916\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32mD:\\DL_Homework\\Kaggle2_Titanic\\Project_Titanic\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001B[0m, in \u001B[0;36mTracingCompiler.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    131\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m    132\u001B[0m   (concrete_function,\n\u001B[0;32m    133\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m--> 134\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    135\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\DL_Homework\\Kaggle2_Titanic\\Project_Titanic\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1741\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1743\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1744\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1745\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1746\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1747\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1748\u001B[0m     args,\n\u001B[0;32m   1749\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1750\u001B[0m     executing_eagerly)\n\u001B[0;32m   1751\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32mD:\\DL_Homework\\Kaggle2_Titanic\\Project_Titanic\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    376\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    377\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 378\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    379\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    380\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    381\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    382\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    383\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    384\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    385\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    386\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    387\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    390\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    391\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32mD:\\DL_Homework\\Kaggle2_Titanic\\Project_Titanic\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 52\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     53\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     55\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "epochs=200\n",
    "verbose=1\n",
    "\n",
    "# Initialize empty lists to store metrics\n",
    "mse_list = []\n",
    "rmse_list = []\n",
    "mae_list = []\n",
    "r2_list = []\n",
    "mape_list = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Perform training epoch\n",
    "    history = model.fit(X_train, y_train, epochs=1, verbose=verbose)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "    # Append metrics to the lists\n",
    "    mse_list.append(mse)\n",
    "    rmse_list.append(rmse)\n",
    "    mae_list.append(mae)\n",
    "    r2_list.append(r2)\n",
    "    mape_list.append(mape)\n",
    "\n",
    "    # Print metrics for the current epoch\n",
    "    print(f\"Epoch {epoch + 1} - MSE: {mse:.4f} - RMSE: {rmse:.4f} - MAE: {mae:.4f} - R2: {r2:.4f} - MAPE: {mape:.2f}%\")\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Epoch': range(1, epochs + 1),\n",
    "    'MSE': mse_list,\n",
    "    'RMSE': rmse_list,\n",
    "    'MAE': mae_list,\n",
    "    'R2': r2_list,\n",
    "    'MAPE': mape_list\n",
    "})\n",
    "\n",
    "# Print the metrics table\n",
    "print(metrics_df)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
